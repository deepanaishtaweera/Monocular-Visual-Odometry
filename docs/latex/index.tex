\label{index_md__home_deeishtay_Documents_Cpp_Monocular_Visual_Odometry_README}%
\Hypertarget{index_md__home_deeishtay_Documents_Cpp_Monocular_Visual_Odometry_README}%


A monocular visual odometry (VO) with 4 components\+: initialization, tracking, local map, and bundle adjustment.

I did this project after I read the \href{htcdtps://github.com/gaoxiang12/slambook}{\texttt{ Slambook}}. ~\newline
 It\textquotesingle{}s also my final project for the course {\ttfamily EESC-\/432 Advanced Computer Vision} in NWU in 2019 March. ~\newline


A demo\+: ~\newline
 

 

In the above figure\+: ~\newline
 {\bfseries{Left}} is a video and the detected key points. ~\newline
 {\bfseries{Right}} is the camera trajectory corresponding to the left video\+: {\bfseries{White}} line is from VO; {\bfseries{Green}} line is ground truth. Red markers on white line are the keyframes. Points are the map points, where points with red color are newly triangulated. ~\newline
 You can download \href{https://github.com/felixchenfy/Data-Storage/raw/master/Monocular-Visual-Odometry/VO_Opti_5frames.avi}{\texttt{ video}} here. ~\newline
\hypertarget{index_autotoc_md24}{}\doxysection{Report}\label{index_autotoc_md24}
My pdf-\/version course report is \href{https://github.com/felixchenfy/Data-Storage/blob/master/Monocular-Visual-Odometry/FeiyuChen_Report_EECS432.pdf}{\texttt{ here}}. It has a more clear decription about the algorithms than this README, so I suggest to read it.\hypertarget{index_autotoc_md25}{}\doxysection{Directory}\label{index_autotoc_md25}

\begin{DoxyItemize}
\item \href{\#Monocular-Visual-Odometry}{\texttt{ Monocular Visual Odometry}}
\item \href{\#Report}{\texttt{ Report}}
\item \href{\#Directory}{\texttt{ Directory}}
\item \href{\#1-Algorithm}{\texttt{ 1. Algorithm}}
\begin{DoxyItemize}
\item \href{\#11-Initialization}{\texttt{ 1.\+1. Initialization}}
\item \href{\#12-Tracking}{\texttt{ 1.\+2. Tracking}}
\item \href{\#13-Local-Map}{\texttt{ 1.\+3. Local Map}}
\item \href{\#14-Bundle-Adjustment}{\texttt{ 1.\+4. Bundle Adjustment}}
\item \href{\#15-Other-details}{\texttt{ 1.\+5. Other details}}
\end{DoxyItemize}
\item \href{\#2-File-Structure}{\texttt{ 2. File Structure}}
\begin{DoxyItemize}
\item \href{\#21-Folders}{\texttt{ 2.\+1. Folders}}
\item \href{\#22-Functions}{\texttt{ 2.\+2. Functions}}
\end{DoxyItemize}
\item \href{\#3-Dependencies}{\texttt{ 3. Dependencies}}
\item \href{\#4-How-to-Run}{\texttt{ 4. How to Run}}
\item \href{\#5-Results}{\texttt{ 5. Results}}
\item \href{\#6-Reference}{\texttt{ 6. Reference}}
\item \href{\#7-To-Do}{\texttt{ 7. To Do}}
\end{DoxyItemize}\hypertarget{index_autotoc_md26}{}\doxysection{1. Algorithm}\label{index_autotoc_md26}
This VO is achieved by the following procedures/algorithms\+:\hypertarget{index_autotoc_md27}{}\doxysubsection{1.\+1. Initialization}\label{index_autotoc_md27}
{\bfseries{Estimate relative camera pose}}\+: ~\newline
 Given a video, set the 1st frame(image) as reference, and do feature matching with the 2nd frame. Compute the {\bfseries{Essential Matrix}} (E) and {\bfseries{Homography Matrix}} (H) between the two frames. Compute their {\bfseries{Symmetric Transfer Error}} by method in \href{https://arxiv.org/abs/1502.00956}{\texttt{ ORB-\/\+SLAM paper}} and choose the better one (i.\+e., choose H if H/(E+H)$>$0.\+45). {\bfseries{Decompose E or H}} into the relative pose between two frames, which is the rotation (R) and translation (t). By using Open\+CV, E gives 1 result, and H gives 2 results, satisfying the criteria that points are in front of camera. For E, only single result to choose; For H, choose the one that makes the image plane and world-\/points plane more parallel.

{\bfseries{Keyframe and local map}}\+: ~\newline
 Insert both 1st and K\+\_\+th frame as {\bfseries{keyframe}}. {\bfseries{Triangulate}} their inlier matched keypoints to obtain the points\textquotesingle{} world positions. These points are called {\bfseries{map points}} and are pushed to {\bfseries{local map}}.

{\bfseries{Check Triangulation Result}} ~\newline
 If the median triangulation angle is smaller than threshold, I will abandon this 2nd frame, and repeat the above process on frame 3, 4, etc. If at frame K, the triangulation angle is large than threshold, the initialization is completed.

{\bfseries{Change scale}}\+: ~\newline
 Scale the translation t to be the same length as the ground truth, so that I can make comparison with ground truth. Then, scale the map points correspondingly.\hypertarget{index_autotoc_md28}{}\doxysubsection{1.\+2. Tracking}\label{index_autotoc_md28}
Keep on estimating the next camera pose. First, find map points that are in the camera view. Do feature matching to find 2d-\/3d correspondance between 3d map points and 2d image keypoints. Estimate camera pose by RANSAC and PnP.\hypertarget{index_autotoc_md29}{}\doxysubsection{1.\+3. Local Map}\label{index_autotoc_md29}
{\bfseries{Insert keyframe\+:}} If the relative pose between current frame and previous keyframe is large enough with a translation or rotation larger than the threshold, insert current frame as a keyframe. ~\newline
 Do feature matching between current and previous keyframe. Get inliers by epipoloar constraint. If a inlier cv\+::\+Key\+Point hasn\textquotesingle{}t been triangulated before, then triangulate it and push it to local map.

{\bfseries{Clean up local map\+:}} Remove map points that are\+: (1) not in current view, (2) whose view\+\_\+angle is larger than threshold, (3) rarely be matched as inlier point. (See Slambook Chapter 9.\+4.)

{\bfseries{Graph/\+Connections between map points and frames\+:}} ~\newline
 Graphs are built at two stages of the algorithm\+: 1) After PnP, based on the 3d-\/2d correspondances, I update the connectionts between map points and current keypoints. 2) During triangulation, I also update the 2d-\/3d correspondance between current keypoints and triangulated mappoints, by either a direct link or going through previous keypoints that have been triangulated.\hypertarget{index_autotoc_md30}{}\doxysubsection{1.\+4. Bundle Adjustment}\label{index_autotoc_md30}
Since I\textquotesingle{}ve built the graph in previous step, I know what the 3d-\/2d point correspondances are in all frames.

Apply optimization to the previous N frames, where the cost function is the sum of reprojection error of each 3d-\/2d point pair. By computing the deriviate wrt (1) points 3d pos and (2) camera poses, we can solve the optimization problem using Gauss-\/\+Newton Method and its variants. These are done by {\bfseries{g2o}} and its built-\/in datatypes of {\ttfamily Vertex\+SBAPoint\+XYZ}, {\ttfamily Vertex\+SE3\+Expmap}, and {\ttfamily Edge\+Project\+XYZ2\+UV}. See Slambook Chapter 4 and Chapter 7.\+8.\+2 for more details.\hypertarget{index_autotoc_md31}{}\doxysubsection{1.\+5. Other details}\label{index_autotoc_md31}
{\bfseries{Image features}}\+: ~\newline
 Extract ORB keypoints and features. Then, a simple grid sampling is applied to obtain keypoints uniformly distributed across image.

{\bfseries{Feature matching}}\+: ~\newline
 Two methods are implemented, where good match is\+: ~\newline
 (1) Feature\textquotesingle{}s distance is smaller than threshold, described in Slambook. ~\newline
 (2) Ratio of smallest and second smallest distance is smaller than threshold, proposed in Prof. Lowe\textquotesingle{}s 2004 SIFT paper. ~\newline
 The first one is adopted, which is easier to tune the parameters to generate fewer error matches. ~\newline
\hypertarget{index_autotoc_md32}{}\doxysection{2. File Structure}\label{index_autotoc_md32}
\hypertarget{index_autotoc_md33}{}\doxysubsection{2.\+1. Folders}\label{index_autotoc_md33}

\begin{DoxyItemize}
\item \href{include/}{\texttt{ include/}}\+: c++ header files.
\item \href{src/}{\texttt{ src/}}\+: c++ definitions.
\item \href{test/}{\texttt{ test/}}\+: Testing scripts for c++ functions.
\item \href{data/}{\texttt{ data/}}\+: Store images.
\end{DoxyItemize}

Main scripts and classes for VO are in \href{include/my_slam/vo/}{\texttt{ include/my\+\_\+slam/vo/}}. I referenced this structure from the \href{https://github.com/gaoxiang12/slambook/tree/master/project/0.4}{\texttt{ Slambook Chapter 9}}.\hypertarget{index_autotoc_md34}{}\doxysubsection{2.\+2. Functions}\label{index_autotoc_md34}
Functions are declared in \href{include/}{\texttt{ include/}}. Some of its folders contain a README. See the tree structure for overview\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{include/}
\DoxyCodeLine{└── my\_slam}
\DoxyCodeLine{    ├── basics}
\DoxyCodeLine{    │   ├── basics.h}
\DoxyCodeLine{    │   ├── config.h}
\DoxyCodeLine{    │   ├── yaml.h}
\DoxyCodeLine{    │   ├── eigen\_funcs.h}
\DoxyCodeLine{    │   ├── opencv\_funcs.h}
\DoxyCodeLine{    │   └── README.md}
\DoxyCodeLine{    ├── common\_include.h}
\DoxyCodeLine{    ├── display}
\DoxyCodeLine{    │   ├── pcl\_display.h}
\DoxyCodeLine{    │   └── pcl\_display\_lib.h}
\DoxyCodeLine{    ├── geometry}
\DoxyCodeLine{    │   ├── camera.h}
\DoxyCodeLine{    │   ├── epipolar\_geometry.h}
\DoxyCodeLine{    │   ├── feature\_match.h}
\DoxyCodeLine{    │   └── motion\_estimation.h}
\DoxyCodeLine{    ├── optimization}
\DoxyCodeLine{    │   └── g2o\_ba.h}
\DoxyCodeLine{    └── vo}
\DoxyCodeLine{        ├── frame.h}
\DoxyCodeLine{        ├── map.h}
\DoxyCodeLine{        ├── mappoint.h}
\DoxyCodeLine{        ├── README.md}
\DoxyCodeLine{        ├── vo\_commons.h}
\DoxyCodeLine{        ├── vo\_io.h}
\DoxyCodeLine{        └── vo.h}

\end{DoxyCode}
\hypertarget{index_autotoc_md35}{}\doxysection{3. Dependencies}\label{index_autotoc_md35}
Require\+: Open\+CV, Eigen, Sophus, g2o. ~\newline
 See details below\+:

$\ast$$\ast$(1) Open\+CV 4.\+0$\ast$$\ast$ ~\newline
 Tutorial for install Open\+CV 4.\+0\+: \href{https://www.pyimagesearch.com/2018/08/15/how-to-install-opencv-4-on-ubuntu/}{\texttt{ link}}.

You may need a version newer than 3.\+4.\+5, because I used this function\+: ~\newline
 {\ttfamily filter\+Homography\+Decomp\+By\+Visible\+Refpoints}, which appears in Open\+CV 3.\+4.\+5.

$\ast$$\ast$(2) Eigen 3$\ast$$\ast$ ~\newline
 It\textquotesingle{}s about matrix arithmetic. See its \href{http://eigen.tuxfamily.org/index.php?title=Main_Page}{\texttt{ official page}}. Install by\+: ~\newline
 \begin{quote}
\$ sudo apt-\/get install libeigen3-\/dev \end{quote}
(Note\+: Eigen only has header files. No \char`\"{}.\+so\char`\"{} or \char`\"{}.\+a\char`\"{} files.)

$\ast$$\ast$(3) Sophus$\ast$$\ast$ ~\newline


It\textquotesingle{}s based on Eigen, and contains datatypes for Lie Group and Lie Algebra (SE3/\+SO3/se3/so3).

Download this lib here\+: \href{https://github.com/strasdat/Sophus}{\texttt{ https\+://github.\+com/strasdat/\+Sophus}}. Do cmake and make. Since I failed to make install it, I manually moved “/\+Sophus/sophus” to “/usr/include/sophus”, and moved “lib\+Sophus.\+so” to “usr/lib”. Then, in my CMake\+Lists.\+txt, I add this\+: {\ttfamily set (THIRD\+\_\+\+PARTY\+\_\+\+LIBS lib\+Sophus.\+so )}.

If there is an error of \char`\"{}unit\+\_\+complex\+\_\+.\+real() = 1.;\char`\"{} replace it and its following line with \char`\"{}unit\+\_\+complex\+\_\+ = std\+::complex$<$double$>$(1,0);\char`\"{}

$\ast$$\ast$(4) g2o$\ast$$\ast$ ~\newline


First install either of the following two packages\+: \begin{quote}
\$ sudo apt-\/get install libsuitesparse \$ sudo apt-\/get install libsuitesparse-\/dev \end{quote}
Download here\+: \href{https://github.com/RainerKuemmerle/g2o}{\texttt{ https\+://github.\+com/\+Rainer\+Kuemmerle/g2o}}. ~\newline
 Checkout to the last version in year 2017. Do cmake, make, make install.\hypertarget{index_autotoc_md36}{}\doxysection{4. How to Run}\label{index_autotoc_md36}
\begin{quote}
\$ mkdir build \&\& mkdir lib \&\& mkdir bin ~\newline
 \$ cd build \&\& cmake .. \&\& make \&\& cd .. ~\newline
 \end{quote}
Then, set up things in \href{config/config.yaml}{\texttt{ config/config.\+yaml}}, and run\+: ~\newline
 \begin{quote}
\$ bin/run\+\_\+vo config/config.\+yaml ~\newline
 \end{quote}
\hypertarget{index_autotoc_md37}{}\doxysection{5. Results}\label{index_autotoc_md37}
I tested the current implementation on \href{https://vision.in.tum.de/data/datasets/rgbd-dataset/download}{\texttt{ TUM}} fr1\+\_\+desk and fr1\+\_\+xyz dataset, but both performances are {\bfseries{bad}}. I guess its due to too few detected keypoints, which causes too few keypoints matches. The {\bfseries{solution}} I guess is to use the ORB-\/\+SLAM\textquotesingle{}s method for extracting enough uniformly destributed keypoints across different scales, and doing guided matching based on the estimated camera motion.

Despite bad performance on fr1 dataset, my program does work well on this \href{http://cvlab.cs.tsukuba.ac.jp/}{\texttt{ New Tsukuba Stereo Database}}, whose images and scenes are synthetic and have abundant high quality keypoints. The results are shown below.

I tested my VO with 3 different settings\+: (1) No optimization. (2) Optimize on map points and current camera pose. (3) Optimize on previous 5 camera poses. See videos below\+:

(1) No optimization\+: 

 

(2) Optimize on points + current pose\+: 

 

(2) Optimize on prev 5 poses\+: 

 

The result shows\+: (1) Optimization improves accuracy. (2) The estiamted trajectory is close to the ground truth.\hypertarget{index_autotoc_md38}{}\doxysection{6. Reference}\label{index_autotoc_md38}
$\ast$$\ast$(1) Slambook$\ast$$\ast$\+: ~\newline
 I read this Dr. Xiang Gao\textquotesingle{}s \href{https://github.com/gaoxiang12/slambook}{\texttt{ Slambook}} before writing code. The book provides both v\+SLAM theory as well as easy-\/to-\/read code examples in every chapter.

The framework of my program is based on Chapter 9 of Slambook, which is a RGB-\/D visual odometry project. Classes declared in \href{include/vo/}{\texttt{ include/vo/}} are based on this Chapter.

These files are mainly copied or built on top of the Slambook\textquotesingle{}s code\+:
\begin{DoxyItemize}
\item CMake\+Lists.\+txt
\item \href{include/basics/config.h}{\texttt{ include/basics/config.\+h}}.
\item \href{include/optimization/g2o_ba.h}{\texttt{ include/optimization/g2o\+\_\+ba.\+h}}.
\end{DoxyItemize}

I also borrowed other codes from the slambook. But since they are small pieces and lines, I didn\textquotesingle{}t list them here.

In short, the Slambook provides huge help for me and my this project.

$\ast$$\ast$(2) Matlab VO tutorial$\ast$$\ast$\+: ~\newline
 \href{https://www.mathworks.com/help/vision/examples/monocular-visual-odometry.html?searchHighlight=visual\%20odometry&s_tid=doc_srchtitle}{\texttt{ This}} is a matlab tutorial of monocular visual odometry. Since Slambook doesn\textquotesingle{}t write a lot about monocular VO, I resorted to this Matlab tutorial for solution. It helped me a lot for getting clear the whole workflow.

The dataset I used is also the same as this Matlab tutorial, which is the \href{http://cvlab.cs.tsukuba.ac.jp/}{\texttt{ New Tsukuba Stereo Database}}.

$\ast$$\ast$(3) ORB-\/\+SLAM/\+ORB-\/\+SLAM2 papers$\ast$$\ast$

I borrowed its code of the criteria for choosing Essential or Homography (for decomposition to obtain relative camera pose.). The copied functions are {\ttfamily check\+Essential\+Score} and {\ttfamily check\+Homography\+Score} in \href{include/geometry/motion_estimation.h}{\texttt{ motion\+\_\+estimation.\+h}}.\hypertarget{index_autotoc_md39}{}\doxysection{7. To Do}\label{index_autotoc_md39}
{\bfseries{Improvements}} ~\newline



\begin{DoxyItemize}
\item In bundle adjustment, I cannot optimize (1) multiple frames and (b) map points {\bfseries{at the same time}}. It returns huge error. I haven\textquotesingle{}t figure out why.
\item If certain region of the image has only few keypoints, then extract more.
\item Utilize epipolar constraint to do feature matching. 
\end{DoxyItemize}