<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Test Project: Monocular Visual Odometry</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Test Project
   &#160;<span id="projectnumber">1.0.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Monocular Visual Odometry </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md__home_deeishtay_Documents_Cpp_Monocular_Visual_Odometry_README"></a></p>
<p>A monocular visual odometry (VO) with 4 components: initialization, tracking, local map, and bundle adjustment.</p>
<p>I did this project after I read the <a href="htcdtps://github.com/gaoxiang12/slambook">Slambook</a>. <br  />
 It's also my final project for the course <code>EESC-432 Advanced Computer Vision</code> in NWU in 2019 March. <br  />
</p>
<p align="center">A demo: <br  />
 </p>
<p><img src="https://github.com/felixchenfy/Data-Storage/raw/master/Monocular-Visual-Odometry/VO_Opti_5frames.gif" alt="" height="240px" class="inline"/> </p>
<p>In the above figure: <br  />
 <b>Left</b> is a video and the detected key points. <br  />
 <b>Right</b> is the camera trajectory corresponding to the left video: <b>White</b> line is from VO; <b>Green</b> line is ground truth. Red markers on white line are the keyframes. Points are the map points, where points with red color are newly triangulated. <br  />
 You can download <a href="https://github.com/felixchenfy/Data-Storage/raw/master/Monocular-Visual-Odometry/VO_Opti_5frames.avi">video</a> here. <br  />
</p>
<h1><a class="anchor" id="autotoc_md24"></a>
Report</h1>
<p>My pdf-version course report is <a href="https://github.com/felixchenfy/Data-Storage/blob/master/Monocular-Visual-Odometry/FeiyuChen_Report_EECS432.pdf">here</a>. It has a more clear decription about the algorithms than this README, so I suggest to read it.</p>
<h1><a class="anchor" id="autotoc_md25"></a>
Directory</h1>
<ul>
<li><a href="#Monocular-Visual-Odometry">Monocular Visual Odometry</a></li>
<li><a href="#Report">Report</a></li>
<li><a href="#Directory">Directory</a></li>
<li><a href="#1-Algorithm">1. Algorithm</a><ul>
<li><a href="#11-Initialization">1.1. Initialization</a></li>
<li><a href="#12-Tracking">1.2. Tracking</a></li>
<li><a href="#13-Local-Map">1.3. Local Map</a></li>
<li><a href="#14-Bundle-Adjustment">1.4. Bundle Adjustment</a></li>
<li><a href="#15-Other-details">1.5. Other details</a></li>
</ul>
</li>
<li><a href="#2-File-Structure">2. File Structure</a><ul>
<li><a href="#21-Folders">2.1. Folders</a></li>
<li><a href="#22-Functions">2.2. Functions</a></li>
</ul>
</li>
<li><a href="#3-Dependencies">3. Dependencies</a></li>
<li><a href="#4-How-to-Run">4. How to Run</a></li>
<li><a href="#5-Results">5. Results</a></li>
<li><a href="#6-Reference">6. Reference</a></li>
<li><a href="#7-To-Do">7. To Do</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md26"></a>
1. Algorithm</h1>
<p>This VO is achieved by the following procedures/algorithms:</p>
<h2><a class="anchor" id="autotoc_md27"></a>
1.1. Initialization</h2>
<p><b>Estimate relative camera pose</b>: <br  />
 Given a video, set the 1st frame(image) as reference, and do feature matching with the 2nd frame. Compute the <b>Essential Matrix</b> (E) and <b>Homography Matrix</b> (H) between the two frames. Compute their <b>Symmetric Transfer Error</b> by method in <a href="https://arxiv.org/abs/1502.00956">ORB-SLAM paper</a> and choose the better one (i.e., choose H if H/(E+H)&gt;0.45). <b>Decompose E or H</b> into the relative pose between two frames, which is the rotation (R) and translation (t). By using OpenCV, E gives 1 result, and H gives 2 results, satisfying the criteria that points are in front of camera. For E, only single result to choose; For H, choose the one that makes the image plane and world-points plane more parallel.</p>
<p><b>Keyframe and local map</b>: <br  />
 Insert both 1st and K_th frame as <b>keyframe</b>. <b>Triangulate</b> their inlier matched keypoints to obtain the points' world positions. These points are called <b>map points</b> and are pushed to <b>local map</b>.</p>
<p><b>Check Triangulation Result</b> <br  />
 If the median triangulation angle is smaller than threshold, I will abandon this 2nd frame, and repeat the above process on frame 3, 4, etc. If at frame K, the triangulation angle is large than threshold, the initialization is completed.</p>
<p><b>Change scale</b>: <br  />
 Scale the translation t to be the same length as the ground truth, so that I can make comparison with ground truth. Then, scale the map points correspondingly.</p>
<h2><a class="anchor" id="autotoc_md28"></a>
1.2. Tracking</h2>
<p>Keep on estimating the next camera pose. First, find map points that are in the camera view. Do feature matching to find 2d-3d correspondance between 3d map points and 2d image keypoints. Estimate camera pose by RANSAC and PnP.</p>
<h2><a class="anchor" id="autotoc_md29"></a>
1.3. Local Map</h2>
<p><b>Insert keyframe:</b> If the relative pose between current frame and previous keyframe is large enough with a translation or rotation larger than the threshold, insert current frame as a keyframe. <br  />
 Do feature matching between current and previous keyframe. Get inliers by epipoloar constraint. If a inlier cv::KeyPoint hasn't been triangulated before, then triangulate it and push it to local map.</p>
<p><b>Clean up local map:</b> Remove map points that are: (1) not in current view, (2) whose view_angle is larger than threshold, (3) rarely be matched as inlier point. (See Slambook Chapter 9.4.)</p>
<p><b>Graph/Connections between map points and frames:</b> <br  />
 Graphs are built at two stages of the algorithm: 1) After PnP, based on the 3d-2d correspondances, I update the connectionts between map points and current keypoints. 2) During triangulation, I also update the 2d-3d correspondance between current keypoints and triangulated mappoints, by either a direct link or going through previous keypoints that have been triangulated.</p>
<h2><a class="anchor" id="autotoc_md30"></a>
1.4. Bundle Adjustment</h2>
<p>Since I've built the graph in previous step, I know what the 3d-2d point correspondances are in all frames.</p>
<p>Apply optimization to the previous N frames, where the cost function is the sum of reprojection error of each 3d-2d point pair. By computing the deriviate wrt (1) points 3d pos and (2) camera poses, we can solve the optimization problem using Gauss-Newton Method and its variants. These are done by <b>g2o</b> and its built-in datatypes of <code>VertexSBAPointXYZ</code>, <code>VertexSE3Expmap</code>, and <code>EdgeProjectXYZ2UV</code>. See Slambook Chapter 4 and Chapter 7.8.2 for more details.</p>
<h2><a class="anchor" id="autotoc_md31"></a>
1.5. Other details</h2>
<p><b>Image features</b>: <br  />
 Extract ORB keypoints and features. Then, a simple grid sampling is applied to obtain keypoints uniformly distributed across image.</p>
<p><b>Feature matching</b>: <br  />
 Two methods are implemented, where good match is: <br  />
 (1) Feature's distance is smaller than threshold, described in Slambook. <br  />
 (2) Ratio of smallest and second smallest distance is smaller than threshold, proposed in Prof. Lowe's 2004 SIFT paper. <br  />
 The first one is adopted, which is easier to tune the parameters to generate fewer error matches. <br  />
</p>
<h1><a class="anchor" id="autotoc_md32"></a>
2. File Structure</h1>
<h2><a class="anchor" id="autotoc_md33"></a>
2.1. Folders</h2>
<ul>
<li><a href="include/">include/</a>: c++ header files.</li>
<li><a href="src/">src/</a>: c++ definitions.</li>
<li><a href="test/">test/</a>: Testing scripts for c++ functions.</li>
<li><a href="data/">data/</a>: Store images.</li>
</ul>
<p>Main scripts and classes for VO are in <a href="include/my_slam/vo/">include/my_slam/vo/</a>. I referenced this structure from the <a href="https://github.com/gaoxiang12/slambook/tree/master/project/0.4">Slambook Chapter 9</a>.</p>
<h2><a class="anchor" id="autotoc_md34"></a>
2.2. Functions</h2>
<p>Functions are declared in <a href="include/">include/</a>. Some of its folders contain a README. See the tree structure for overview:</p>
<div class="fragment"><div class="line">include/</div>
<div class="line">└── my_slam</div>
<div class="line">    ├── basics</div>
<div class="line">    │   ├── basics.h</div>
<div class="line">    │   ├── config.h</div>
<div class="line">    │   ├── yaml.h</div>
<div class="line">    │   ├── eigen_funcs.h</div>
<div class="line">    │   ├── opencv_funcs.h</div>
<div class="line">    │   └── README.md</div>
<div class="line">    ├── common_include.h</div>
<div class="line">    ├── display</div>
<div class="line">    │   ├── pcl_display.h</div>
<div class="line">    │   └── pcl_display_lib.h</div>
<div class="line">    ├── geometry</div>
<div class="line">    │   ├── camera.h</div>
<div class="line">    │   ├── epipolar_geometry.h</div>
<div class="line">    │   ├── feature_match.h</div>
<div class="line">    │   └── motion_estimation.h</div>
<div class="line">    ├── optimization</div>
<div class="line">    │   └── g2o_ba.h</div>
<div class="line">    └── vo</div>
<div class="line">        ├── frame.h</div>
<div class="line">        ├── map.h</div>
<div class="line">        ├── mappoint.h</div>
<div class="line">        ├── README.md</div>
<div class="line">        ├── vo_commons.h</div>
<div class="line">        ├── vo_io.h</div>
<div class="line">        └── vo.h</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md35"></a>
3. Dependencies</h1>
<p>Require: OpenCV, Eigen, Sophus, g2o. <br  />
 See details below:</p>
<p>**(1) OpenCV 4.0** <br  />
 Tutorial for install OpenCV 4.0: <a href="https://www.pyimagesearch.com/2018/08/15/how-to-install-opencv-4-on-ubuntu/">link</a>.</p>
<p>You may need a version newer than 3.4.5, because I used this function: <br  />
 <code>filterHomographyDecompByVisibleRefpoints</code>, which appears in OpenCV 3.4.5.</p>
<p>**(2) Eigen 3** <br  />
 It's about matrix arithmetic. See its <a href="http://eigen.tuxfamily.org/index.php?title=Main_Page">official page</a>. Install by: <br  />
 </p><blockquote class="doxtable">
<p>$ sudo apt-get install libeigen3-dev </p>
</blockquote>
<p>(Note: Eigen only has header files. No ".so" or ".a" files.)</p>
<p>**(3) Sophus** <br  />
</p>
<p>It's based on Eigen, and contains datatypes for Lie Group and Lie Algebra (SE3/SO3/se3/so3).</p>
<p>Download this lib here: <a href="https://github.com/strasdat/Sophus">https://github.com/strasdat/Sophus</a>. Do cmake and make. Since I failed to make install it, I manually moved “/Sophus/sophus” to “/usr/include/sophus”, and moved “libSophus.so” to “usr/lib”. Then, in my CMakeLists.txt, I add this: <code>set (THIRD_PARTY_LIBS libSophus.so )</code>.</p>
<p>If there is an error of "unit_complex_.real() = 1.;" replace it and its following line with "unit_complex_ = std::complex&lt;double&gt;(1,0);"</p>
<p>**(4) g2o** <br  />
</p>
<p>First install either of the following two packages: </p><blockquote class="doxtable">
<p>$ sudo apt-get install libsuitesparse $ sudo apt-get install libsuitesparse-dev </p>
</blockquote>
<p>Download here: <a href="https://github.com/RainerKuemmerle/g2o">https://github.com/RainerKuemmerle/g2o</a>. <br  />
 Checkout to the last version in year 2017. Do cmake, make, make install.</p>
<h1><a class="anchor" id="autotoc_md36"></a>
4. How to Run</h1>
<blockquote class="doxtable">
<p>$ mkdir build &amp;&amp; mkdir lib &amp;&amp; mkdir bin <br  />
 $ cd build &amp;&amp; cmake .. &amp;&amp; make &amp;&amp; cd .. <br  />
 </p>
</blockquote>
<p>Then, set up things in <a href="config/config.yaml">config/config.yaml</a>, and run: <br  />
 </p><blockquote class="doxtable">
<p>$ bin/run_vo config/config.yaml <br  />
 </p>
</blockquote>
<h1><a class="anchor" id="autotoc_md37"></a>
5. Results</h1>
<p>I tested the current implementation on <a href="https://vision.in.tum.de/data/datasets/rgbd-dataset/download">TUM</a> fr1_desk and fr1_xyz dataset, but both performances are <b>bad</b>. I guess its due to too few detected keypoints, which causes too few keypoints matches. The <b>solution</b> I guess is to use the ORB-SLAM's method for extracting enough uniformly destributed keypoints across different scales, and doing guided matching based on the estimated camera motion.</p>
<p>Despite bad performance on fr1 dataset, my program does work well on this <a href="http://cvlab.cs.tsukuba.ac.jp/">New Tsukuba Stereo Database</a>, whose images and scenes are synthetic and have abundant high quality keypoints. The results are shown below.</p>
<p>I tested my VO with 3 different settings: (1) No optimization. (2) Optimize on map points and current camera pose. (3) Optimize on previous 5 camera poses. See videos below:</p>
<p align="center">(1) No optimization: </p>
<p><img src="https://github.com/felixchenfy/Data-Storage/raw/master/Monocular-Visual-Odometry/VO_No_Opti.gif" alt="" height="240px" class="inline"/> </p>
<p align="center">(2) Optimize on points + current pose: </p>
<p><img src="https://github.com/felixchenfy/Data-Storage/raw/master/Monocular-Visual-Odometry/VO_Opti_1frame_and_points.gif" alt="" height="240px" class="inline"/> </p>
<p align="center">(2) Optimize on prev 5 poses: </p>
<p><img src="https://github.com/felixchenfy/Data-Storage/raw/master/Monocular-Visual-Odometry/VO_Opti_5frames.gif" alt="" height="240px" class="inline"/> </p>
<p>The result shows: (1) Optimization improves accuracy. (2) The estiamted trajectory is close to the ground truth.</p>
<h1><a class="anchor" id="autotoc_md38"></a>
6. Reference</h1>
<p>**(1) Slambook**: <br  />
 I read this Dr. Xiang Gao's <a href="https://github.com/gaoxiang12/slambook">Slambook</a> before writing code. The book provides both vSLAM theory as well as easy-to-read code examples in every chapter.</p>
<p>The framework of my program is based on Chapter 9 of Slambook, which is a RGB-D visual odometry project. Classes declared in <a href="include/vo/">include/vo/</a> are based on this Chapter.</p>
<p>These files are mainly copied or built on top of the Slambook's code:</p><ul>
<li>CMakeLists.txt</li>
<li><a href="include/basics/config.h">include/basics/config.h</a>.</li>
<li><a href="include/optimization/g2o_ba.h">include/optimization/g2o_ba.h</a>.</li>
</ul>
<p>I also borrowed other codes from the slambook. But since they are small pieces and lines, I didn't list them here.</p>
<p>In short, the Slambook provides huge help for me and my this project.</p>
<p>**(2) Matlab VO tutorial**: <br  />
 <a href="https://www.mathworks.com/help/vision/examples/monocular-visual-odometry.html?searchHighlight=visual%20odometry&amp;s_tid=doc_srchtitle">This</a> is a matlab tutorial of monocular visual odometry. Since Slambook doesn't write a lot about monocular VO, I resorted to this Matlab tutorial for solution. It helped me a lot for getting clear the whole workflow.</p>
<p>The dataset I used is also the same as this Matlab tutorial, which is the <a href="http://cvlab.cs.tsukuba.ac.jp/">New Tsukuba Stereo Database</a>.</p>
<p>**(3) ORB-SLAM/ORB-SLAM2 papers**</p>
<p>I borrowed its code of the criteria for choosing Essential or Homography (for decomposition to obtain relative camera pose.). The copied functions are <code>checkEssentialScore</code> and <code>checkHomographyScore</code> in <a href="include/geometry/motion_estimation.h">motion_estimation.h</a>.</p>
<h1><a class="anchor" id="autotoc_md39"></a>
7. To Do</h1>
<p><b>Improvements</b> <br  />
</p>
<ul>
<li>In bundle adjustment, I cannot optimize (1) multiple frames and (b) map points <b>at the same time</b>. It returns huge error. I haven't figure out why.</li>
<li>If certain region of the image has only few keypoints, then extract more.</li>
<li>Utilize epipolar constraint to do feature matching. </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
